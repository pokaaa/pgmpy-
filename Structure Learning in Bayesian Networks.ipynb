{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we show examples for using the Structure Learning Algorithms in pgmpy. Currently, pgmpy has implementation of 3 main algorithms:\n",
    "1. PC with stable and parallel variants.\n",
    "2. Hill-Climb Search\n",
    "3. Exhaustive Search\n",
    "\n",
    "For PC the following conditional independence test can be used:\n",
    "1. Chi-Square test (https://en.wikipedia.org/wiki/Chi-squared_test)\n",
    "2. Pearsonr (https://en.wikipedia.org/wiki/Partial_correlation#Using_linear_regression)\n",
    "3. G-squared (https://en.wikipedia.org/wiki/G-test)\n",
    "4. Log-likelihood (https://en.wikipedia.org/wiki/G-test)\n",
    "5. Freeman-Tuckey (Read, Campbell B. \"Freeman—Tukey chi-squared goodness-of-fit statistics.\" Statistics & probability letters 18.4 (1993): 271-278.)\n",
    "6. Modified Log-likelihood\n",
    "7. Neymann (https://en.wikipedia.org/wiki/Neyman%E2%80%93Pearson_lemma)\n",
    "8. Cressie Read (Cressie, Noel, and Timothy RC Read. \"Multinomial goodness‐of‐fit tests.\" Journal of the Royal Statistical Society: Series B (Methodological) 46.3 (1984): 440-464)\n",
    "9. Power Divergence (Cressie, Noel, and Timothy RC Read. \"Multinomial goodness‐of‐fit tests.\" Journal of the Royal Statistical Society: Series B (Methodological) 46.3 (1984): 440-464.)\n",
    "\n",
    "For Hill-Climb and Exhausitive Search the following scoring methods can be used:\n",
    "1. K2 Score\n",
    "2. BDeu Score\n",
    "3. Bic Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "import networkx as nx\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from pgmpy.estimators import PC, HillClimbSearch, ExhaustiveSearch\n",
    "from pgmpy.estimators import K2Score\n",
    "from pgmpy.utils import get_example_model\n",
    "from pgmpy.sampling import BayesianModelSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating for node: VENTMACH:   0%|          | 0/37 [00:00<?, ?it/s] /home/ankur/pgmpy/examples/pgmpy/factors/discrete/DiscreteFactor.py:517: UserWarning: Found unknown state name. Trying to switch to using all state names as state numbers\n",
      "  warn(\n",
      "Generating for node: CVP: 100%|██████████| 37/37 [00:00<00:00, 150.14it/s]         \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MINVOLSET</th>\n",
       "      <th>VENTMACH</th>\n",
       "      <th>DISCONNECT</th>\n",
       "      <th>VENTTUBE</th>\n",
       "      <th>INTUBATION</th>\n",
       "      <th>PULMEMBOLUS</th>\n",
       "      <th>SHUNT</th>\n",
       "      <th>PAP</th>\n",
       "      <th>FIO2</th>\n",
       "      <th>KINKEDTUBE</th>\n",
       "      <th>...</th>\n",
       "      <th>HRBP</th>\n",
       "      <th>LVFAILURE</th>\n",
       "      <th>HISTORY</th>\n",
       "      <th>HYPOVOLEMIA</th>\n",
       "      <th>STROKEVOLUME</th>\n",
       "      <th>CO</th>\n",
       "      <th>BP</th>\n",
       "      <th>LVEDVOLUME</th>\n",
       "      <th>PCWP</th>\n",
       "      <th>CVP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>ZERO</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>...</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>LOW</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>LOW</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>LOW</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>LOW</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>...</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>LOW</td>\n",
       "      <td>LOW</td>\n",
       "      <td>LOW</td>\n",
       "      <td>LOW</td>\n",
       "      <td>LOW</td>\n",
       "      <td>LOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>...</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>LOW</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NORMAL</td>\n",
       "      <td>LOW</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>ZERO</td>\n",
       "      <td>ONESIDED</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>...</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>LOW</td>\n",
       "      <td>ONESIDED</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>...</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>LOW</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  MINVOLSET VENTMACH DISCONNECT VENTTUBE INTUBATION PULMEMBOLUS   SHUNT  \\\n",
       "0    NORMAL   NORMAL       TRUE     ZERO     NORMAL       FALSE  NORMAL   \n",
       "1    NORMAL   NORMAL      FALSE      LOW     NORMAL       FALSE  NORMAL   \n",
       "2      HIGH     HIGH      FALSE     HIGH     NORMAL       FALSE  NORMAL   \n",
       "3    NORMAL      LOW      FALSE     ZERO   ONESIDED       FALSE    HIGH   \n",
       "4    NORMAL   NORMAL      FALSE      LOW   ONESIDED       FALSE    HIGH   \n",
       "\n",
       "      PAP    FIO2 KINKEDTUBE  ...  HRBP LVFAILURE HISTORY HYPOVOLEMIA  \\\n",
       "0  NORMAL  NORMAL      FALSE  ...  HIGH     FALSE   FALSE       FALSE   \n",
       "1  NORMAL     LOW      FALSE  ...  HIGH      TRUE    TRUE       FALSE   \n",
       "2  NORMAL  NORMAL      FALSE  ...  HIGH     FALSE   FALSE       FALSE   \n",
       "3  NORMAL  NORMAL      FALSE  ...  HIGH     FALSE   FALSE       FALSE   \n",
       "4  NORMAL  NORMAL      FALSE  ...  HIGH     FALSE   FALSE       FALSE   \n",
       "\n",
       "  STROKEVOLUME      CO    BP LVEDVOLUME    PCWP     CVP  \n",
       "0          LOW  NORMAL   LOW     NORMAL  NORMAL  NORMAL  \n",
       "1          LOW     LOW   LOW        LOW     LOW     LOW  \n",
       "2       NORMAL    HIGH   LOW     NORMAL  NORMAL  NORMAL  \n",
       "3       NORMAL    HIGH  HIGH     NORMAL  NORMAL  NORMAL  \n",
       "4       NORMAL    HIGH  HIGH     NORMAL     LOW  NORMAL  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_example_model('alarm')\n",
    "samples = BayesianModelSampling(model).forward_sample(size=int(1e3))\n",
    "samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funtion to evaluate the learned model structures.\n",
    "def get_f1_score(estimated_model, true_model):\n",
    "    nodes = estimated_model.nodes()\n",
    "    est_adj = nx.to_numpy_matrix(estimated_model.to_undirected(), nodelist=nodes, weight=None)\n",
    "    true_adj = nx.to_numpy_matrix(true_model.to_undirected(), nodelist=nodes, weight=None)\n",
    "    \n",
    "    f1 = f1_score(np.ravel(true_adj), np.ravel(est_adj))\n",
    "    print(\"F1-score for the model skeleton: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn the model structure using Hill-Climb Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 61/10000 [00:36<1:39:54,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score for the model skeleton:  0.8076923076923076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "*理论知识：\n",
    "score评分评的是一个模型和所给数据集的贴合程度：\n",
    "\n",
    "一个结构的贝叶斯评分：后验概率 log p(结构|数据)\n",
    "log p(结构|数据)= log p(数据|结构) + log(结构)\n",
    "\n",
    "p(结构)是结构先验分布，一般假设为均匀分布\n",
    "\n",
    "p(数据|结构)是边缘似然函数，展开=对该结构的参数进行积分(p(数据|结构，参数)*p(参数|结构))\n",
    "\n",
    "进行一步一步推理后得到：\n",
    "CH评分：\n",
    "l(结构|数据)= 所有节点i的和（所有父亲j的和（   loggamma(aij*)  \n",
    "                                         -loggamma(aij*+mij*)\n",
    "                                         +所有节点可能取值k的和（loggamma(aijk)\n",
    "                                                          -loggamma(aijk+mijk)                                             \n",
    "                                                        ）\n",
    "                                         ））\n",
    "                            \n",
    "注意：\n",
    "1、由于CH评分是可以分解的，所以可以先对每个节点求分，最后相加。                                       \n",
    "2、在k2算法中，为简化模型计算，\n",
    "   假设所有参数先验分布都是均匀分布：即aijk和aij*都是0\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "*实践：\n",
    "用了k2score但其实不是k2算法，只是k2算法中的评分那部分\n",
    "k2score中local_score函数：\n",
    "计算每一个节点受其可能父节点影响的分值：\n",
    " （1）数据准备\n",
    "        var_states该节点可能的取值\n",
    "                        = self.state_names[variable]\n",
    "        var_cardinality该节点可能取值的个数\n",
    "                        = len(var_states)\n",
    "        state_counts该节点可能取值与父亲们的可能取值组合构成的表\n",
    "                        = self.state_counts(variable, parents)\n",
    "        num_parents_states父亲们可能的组合个数\n",
    "                        = float(state_counts.shape[1])\n",
    "        counts该节点可能取值与父亲们的可能取值组合构成的表转为矩阵\n",
    "                        = np.asarray(state_counts)\n",
    "        log_gamma_counts将counts初始化为0\n",
    "                        = np.zeros_like(counts, dtype=np.float_)\n",
    "\n",
    "   （2）计算 log(gamma(counts + 1))即公式中的log(gamma(aij*+mijk*))\n",
    "        gammaln(counts + 1, out=log_gamma_counts)\n",
    "\n",
    "    (3)计算公式中的  对于该节点所有可能取值k的和（ log(gamma(mijk+aijk)) ）\n",
    "        log_gamma_conds首先计算mijk对于k求和也就是counts的每一列求和\n",
    "                         = np.sum(counts, axis=0, dtype=np.float_)\n",
    "        aijk对于k求和，也就是counts表的每一列的1相加，\n",
    "                       结果都是该节点可能取值个数var_cardinality\n",
    "        gammaln(log_gamma_conds + var_cardinality, out=log_gamma_conds)\n",
    "        \n",
    "   （4）最后合起来计算，对所有父亲求和，也就是np.sum()\n",
    "       首先，注意符号，与公式中相反\n",
    "       其次，省略log(gamma(aij*))的计算，因为所有结构计算出来都相同，因为aij*都为1\n",
    "       最后，对公式中  所有节点可能取值k的和（loggamma(aijk)) 的计算\n",
    "            就是logamma(var_cardinality)，\n",
    "            然后要对所有父亲求和，因此乘以父亲组合的个数num_parantes-states\n",
    "                                                 \n",
    "        score = (\n",
    "            np.sum(log_gamma_counts)\n",
    "            - np.sum(log_gamma_conds)\n",
    "            + num_parents_states * lgamma(var_cardinality)\n",
    "        )\n",
    "        \n",
    "对每个节点的分值计算完毕，由StructureScore中的score函数调用local_score计算总的：\n",
    "        for node in model.nodes():\n",
    "            score += self.local_score(node, model.predecessors(node))\n",
    "\n",
    "\"\"\"  \n",
    "\n",
    "\n",
    "scoring_method = K2Score(data=samples)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "爬山法:\n",
    "从 初始的 无边 模型 出发开始搜索：\n",
    "每一步使用搜索算子(search operator)对当前模型(current model)进行局部修改，\n",
    "得到一系列候选模型(candidate model)，计算每个候选模型的评分，并将最优模型与当前模型比较，\n",
    "若是最优候选模型的评分大，则以它为下一个当前模型，继续搜索\n",
    "否则就停止搜索，并返回当前模型。\n",
    "\n",
    "搜索算子有3个：加边、减边、转边\n",
    "注意：加边和转变不能生成有向圈\n",
    "\n",
    "爬山法可以使用任何评分函数，这里使用k2中的评分方法。\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "est = HillClimbSearch(data=samples)\n",
    "\n",
    "\"\"\"\n",
    "实践：\n",
    "HillClimbSearch类继承StructureEstimator。\n",
    "其中estimate函数：\n",
    "参数： \n",
    "scoring_method：str3选1： \"k2score\"，\"bdeuscore\"，\"bicscore\"\n",
    "                自定义StructureScore\n",
    "start_dag:初始的结构\n",
    "fixed_edges：算法中一直存在且不变的边\n",
    "tabu_length：最后tabu_length个图禁止转边\n",
    "max_indegree：最大父亲节点个数\n",
    "black_list：禁止加入的边\n",
    "white_list：允许加入的边\n",
    "epsilon：评分增加幅度小于epsilon，可以返回了\n",
    "max_iter：最大允许迭代次数，超过返回\n",
    "\n",
    "1、做好准备工作：\n",
    "  （1）检查评分方法3选1或自定义的\n",
    "      \n",
    "  （2）检车初始结构start_dag，只加入点\n",
    "          if start_dag is None:\n",
    "            start_dag = DAG()\n",
    "            start_dag.add_nodes_from(self.variables)\n",
    "            \n",
    "   (3)检查fixed_edges\n",
    "      加入fixed_edges到start_dag中\n",
    "      \n",
    "  （4）准备好white_list和black_list\n",
    "  \n",
    "  （5）初始化max_indegree为inf、current_model为start_dag，tabu_list\n",
    "  \n",
    "2、开始迭代，每轮迭代找到最高分的作为下一个current_model\n",
    "每一轮迭代中，调用_legal_operation函数：\n",
    "  （1）获得所有加边的合法操作\n",
    "      potential_new_edges = (\n",
    "            set(permutations(self.variables, 2))#permutations获得所有排列\n",
    "            - set(model.edges())#删掉已存在的边\n",
    "            - set([(Y, X) for (X, Y) in model.edges()])#删掉已存在的边的转向边\n",
    "        )\n",
    "      如果加入potential_new_edges中的一条边（x,y）不会导致有向圈\n",
    "         令operation=(\"+\"(x,y))\n",
    "         如果operation不在tabu_list\n",
    "         并且不在black_list\n",
    "         并且在white_list\n",
    "            old_parents设为Y原来父亲\n",
    "            new_parents设为y原来父亲+x\n",
    "            如果new_parents个数<max_indegree\n",
    "              score_delta = score(Y, new_parents) - score(Y, old_parents)\n",
    "              yield (operation, score_delta)\n",
    "      \n",
    "  \n",
    "  （2）获得所有合法删边操作\n",
    "          for (X, Y) in model.edges():\n",
    "            operation = (\"-\", (X, Y))\n",
    "            if (operation not in tabu_list) and ((X, Y) not in fixed_edges):\n",
    "                old_parents = model.get_parents(Y)\n",
    "                new_parents = old_parents[:]\n",
    "                new_parents.remove(X)\n",
    "                score_delta = score(Y, new_parents) - score(Y, old_parents)\n",
    "                yield (operation, score_delta)\n",
    "  \n",
    "  （3）获得所有合法转边操作(flip edges)\n",
    "      如果不形成环：（xy之间简单路长度大于2则有环）：\n",
    "      如果。。。。。。\n",
    "       score_delta = (\n",
    "                            score(X, new_X_parents)\n",
    "                            + score(Y, new_Y_parents)\n",
    "                            - score(X, old_X_parents)\n",
    "                            - score(Y, old_Y_parents)\n",
    "                        )  \n",
    "  \n",
    "每一迭代中，\n",
    "   获取best_operation, best_score_delta \n",
    "     =max(elf._legal_operations(\n",
    "                    current_model,\n",
    "                    score_fn,\n",
    "                    tabu_list,\n",
    "                    max_indegree,\n",
    "                    black_list,\n",
    "                    white_list,\n",
    "                    fixed_edges,\n",
    "                ),\n",
    "                key=lambda t: t[1],\n",
    "                default=(None, None),\n",
    "        )\n",
    "    若best_operation若空或best_score_delta<epsilon，返回\n",
    "    分情况讨论+/-/flip，分别对current_model进行相应操作\n",
    "    \n",
    "退出迭代后，返回current_model\n",
    "         \n",
    "\"\"\"\n",
    "estimated_model = est.estimate(scoring_method=scoring_method, max_indegree=4, max_iter=int(1e4))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "f1_score为分类问题的一个衡量指标。\n",
    "一些多分类问题的机器学习竞赛，常常将F1-score作为最终测评的方法。\n",
    "它是精确率和召回率的调和平均数，最大为1，最小为0。\n",
    "这里model作为已知的最佳模型，estimated_model为预测的最佳模型\n",
    "F1 = 2 * (precision * recall) / (precision + recall)\n",
    "具体见\n",
    "https://blog.csdn.net/qq_14997473/article/details/82684300\n",
    "\"\"\"\n",
    "\n",
    "get_f1_score(estimated_model, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
